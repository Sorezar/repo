{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction à knn\n---\nLe but de ce TP est de mieux appréhender l'apprentissage via une méthode type 'plus proches voisins'. \n--- \n\n## Conseils\n- Pour chaque question, essayer d'écrire des fonctions plutôt que des scripts\n- Eviter d'avoir deux fonctions qui portent le même nom (redéfinition de la fonction), préférer ajouter un paramètre de choix","metadata":{"_uuid":"eb4bfdf8a11a8189f15da6b32bd628e586a4676b"}},{"cell_type":"markdown","source":"---\n# Construction d'un jeu de données simple\n---\nDans ce TP, on n'utili pas un jeu de données existant, mais on en fabrique un, d'un niveau de complexité adéquat, et dont on connait en réalité parfaitement la loi.","metadata":{}},{"cell_type":"markdown","source":"## Ecrire une fonction ```separation```\n- Entrée :  un couple (x, y) de flottants\n- Sortie : 'A' si y<f(x)  et 'B' sinon, où $f(x) = \\frac{x}{3}*\\left(2+\\cos\\left(\\frac{x}{6}\\right)\\right)$","metadata":{}},{"cell_type":"code","source":"import math as m\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:50:34.060120Z","iopub.execute_input":"2022-03-27T13:50:34.060372Z","iopub.status.idle":"2022-03-27T13:50:34.065466Z","shell.execute_reply.started":"2022-03-27T13:50:34.060342Z","shell.execute_reply":"2022-03-27T13:50:34.064580Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"def sep(x,y):\n    fx = (x/3) * (2+m.cos(x/6))\n    if(y < fx):\n        return 'A'\n    else :\n        return 'B'","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:50:34.066794Z","iopub.execute_input":"2022-03-27T13:50:34.067007Z","iopub.status.idle":"2022-03-27T13:50:34.078439Z","shell.execute_reply.started":"2022-03-27T13:50:34.066979Z","shell.execute_reply":"2022-03-27T13:50:34.077457Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"## Ecrire une fonction ```donneesSimples``` \n- Entrée : \n    - ```N``` un entier \n    - ```f``` une fonction prenant en entrée deux flottants\n- Sortie : un dataframe de ```N``` échantillons de 3 attributs :\n  - ```abscisse``` : tiré en aléatoire uniforme dans [0 ; 100], flottant\n  - ```ordonnee``` : tiré en aléatoire uniforme dans [0 ; 100], flottant\n  - ```classe = f(abscisse, ordonnée)```\n- vous *devez* utiliser un apply de la fonction ```séparation```","metadata":{}},{"cell_type":"code","source":"\ndef donneesSimples(N, f):\n    d = {\"abscisse\":np.random.uniform(0,100,N),\"ordonnée\":np.random.uniform(0,100,N)}\n    df = pd.DataFrame(data = d)\n    df['classe'] = df.apply(lambda row: f(row['abscisse'], row['ordonnée']), axis = 'columns')\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:50:34.080055Z","iopub.execute_input":"2022-03-27T13:50:34.081112Z","iopub.status.idle":"2022-03-27T13:50:34.092473Z","shell.execute_reply.started":"2022-03-27T13:50:34.081056Z","shell.execute_reply":"2022-03-27T13:50:34.091489Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":"  \n## Ecrire une fonction ```representation```\nCette fonction génère une représentation graphique des données dans le plan","metadata":{}},{"cell_type":"code","source":"def get_y(x):\n    return (x/3) * (2+m.cos(x/6))\ndef representation(df):\n    sns.scatterplot(x=df['abscisse'], y=df['ordonnée'], hue=df['classe'])\n    \n    df2 = df['abscisse']\n    df2 = pd.DataFrame(df2)\n    \n    df2['ordonnée']= df2.apply(lambda row: get_y(row['abscisse']), axis = 'columns')\n    sns.lineplot(x=df2['abscisse'], y=df2['ordonnée'])","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:50:34.095247Z","iopub.execute_input":"2022-03-27T13:50:34.095703Z","iopub.status.idle":"2022-03-27T13:50:34.106380Z","shell.execute_reply.started":"2022-03-27T13:50:34.095642Z","shell.execute_reply":"2022-03-27T13:50:34.105255Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":"\n## Créer une BD ```donnees``` de 600 données\n- par application de ```donneesSimples(600 separation)```","metadata":{}},{"cell_type":"code","source":"df = donneesSimples(600, sep)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:50:34.108210Z","iopub.execute_input":"2022-03-27T13:50:34.108482Z","iopub.status.idle":"2022-03-27T13:50:34.136404Z","shell.execute_reply.started":"2022-03-27T13:50:34.108449Z","shell.execute_reply":"2022-03-27T13:50:34.135137Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"markdown","source":"## Représenter la base de donnée graphiquement\nUn scatterplot pour les points et un lineplot pour la séparation théorique donnent un graphique pertinent.","metadata":{}},{"cell_type":"code","source":"representation(df)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:50:34.138381Z","iopub.execute_input":"2022-03-27T13:50:34.138941Z","iopub.status.idle":"2022-03-27T13:50:34.566895Z","shell.execute_reply.started":"2022-03-27T13:50:34.138883Z","shell.execute_reply":"2022-03-27T13:50:34.566159Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"markdown","source":"## En utilisant scikit-learn, séparer ```donnees``` en deux ensembles\nEcrire la fonction , fonction ```creerBases``` qui sépare la base de données en :\n- apprentissage (et validation) : 50%\n- validation et test 50%  \n \n**NB** : dans ce TP, l'ensemble de test servira d'ensemble de validation.\n\n**NB2** : à la fin de cette étape, on doit disposer de deux dataframes, un pour l'apprentissage, un pour validation/test","metadata":{"_uuid":"1f8e66c76444474c61a98793a53d65af4392dfad"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef creerBases(df):\n\n    X = df.iloc[:,:2]\n    y = df.classe\n\n    train_X, test_X, train_Y, test_Y = train_test_split(X, y, test_size=0.5, stratify=y, random_state=1)\n    \n    return X,y,train_X, test_X,train_Y, test_Y \n\nX,y,train_X, test_X,train_Y, test_Y = creerBases(df)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:50:34.568299Z","iopub.execute_input":"2022-03-27T13:50:34.568720Z","iopub.status.idle":"2022-03-27T13:50:34.578607Z","shell.execute_reply.started":"2022-03-27T13:50:34.568653Z","shell.execute_reply":"2022-03-27T13:50:34.577798Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"markdown","source":"# Théorie et sa mise en pratique dans sklearn\n- Rappeler le fonctionnement de la classification par knn\n- Expliquer les variations proposées par 'algorithm'\n- Expliquer l'influence de 'p' dans la distance de Minkowski (exemples à l'appui)\n- Expliquer l'influence de 'weight' (exemples à l'appui)","metadata":{}},{"cell_type":"markdown","source":"Le but de la classification par KNN c'est de déterminer la classe de points inconnu par rapport à leur distance avec leurs plus proches voisins dont la classe est connu","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import balanced_accuracy_score\n\nknn = KNeighborsClassifier()\nknn.fit(train_X,train_Y)\nprediction = knn.predict(test_X)\ndisplay(balanced_accuracy_score(test_Y, prediction))\n\nknn = KNeighborsClassifier(p = 1)\nknn.fit(train_X,train_Y)\nprediction = knn.predict(test_X)\ndisplay(balanced_accuracy_score(test_Y, prediction))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:50:34.579908Z","iopub.execute_input":"2022-03-27T13:50:34.580727Z","iopub.status.idle":"2022-03-27T13:50:34.635303Z","shell.execute_reply.started":"2022-03-27T13:50:34.580683Z","shell.execute_reply":"2022-03-27T13:50:34.634152Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"markdown","source":"# Représenter la surface de séparation en fonction du nombre de voisins\n## Fonction de coloration\nEcrire une fonction ```colorationPlan``` qui produit une représentation [0 ; 100]x[0 ; 100] colorée en fonction de la classe attribuée par votre classifieur.\nen fonction de la classe attribuée par votre classifieur à chacun de ses points.\n- Entrées : \n    - ```classifieur``` une fonction de classification (pour vérifier votre code, prenez un classifieur de votre choix dans sklearn)\n    - ```NbPts``` nombre de points à prendre dans chaque direction pour discrétiser [0 ; 100]x[0 ; 100]","metadata":{}},{"cell_type":"code","source":"import itertools as it\ndef colorationPlan(classifieur, NbPts):\n        X = np.linspace(0,100,NbPts)\n        combinations = it.product(X,X)\n        df = pd.DataFrame(combinations, columns =['abscisse', 'ordonnée'])\n        predictions = knn.predict(df)\n        df['classe'] = predictions\n        representation(df)\ncolorationPlan(knn, 200)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:50:34.637273Z","iopub.execute_input":"2022-03-27T13:50:34.638369Z","iopub.status.idle":"2022-03-27T13:50:47.320594Z","shell.execute_reply.started":"2022-03-27T13:50:34.638315Z","shell.execute_reply":"2022-03-27T13:50:47.319922Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":"## Observer et analyser l'influence du choix de 'k' sur la classification obtenue\nPour différentes valeurs de ```k``` dans le classifieur, utiliser la fonction ```colorationPlan``` et comparer les résultats.","metadata":{}},{"cell_type":"code","source":"def knnf(k):\n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(train_X,train_Y)\n    return knn\n\nknn = knnf(1)\ncolorationPlan(knn, 200)\nplt.figure()\nknn = knnf(3)\ncolorationPlan(knn, 200)\nplt.figure()\nknn = knnf(5)\ncolorationPlan(knn, 200)\nplt.figure()\nknn = knnf(11)\ncolorationPlan(knn, 200)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:50:47.321972Z","iopub.execute_input":"2022-03-27T13:50:47.322368Z","iopub.status.idle":"2022-03-27T13:51:37.673698Z","shell.execute_reply.started":"2022-03-27T13:50:47.322315Z","shell.execute_reply":"2022-03-27T13:51:37.672923Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"markdown","source":"## Commenter\n- Essayer d'expliquer les résultats obtenus\n- Entre deux résultats équivalents pour deux valeurs de 'k' différentes, lequel choisir ?","metadata":{"_uuid":"47cc30607750781e8bb9351ac418ce3a9ffe96d4"}},{"cell_type":"markdown","source":"Les résultats sont très similaires néanmoins, les points au-dessus de la courbe ont tendance à avoir la même classe que ceux en-dessous car leurs voisins direct sont en-dessous de celle-ci ce qui donne une impression de débordements dans les prédictions des valeurs au-dessus de la courbe.\n","metadata":{}},{"cell_type":"markdown","source":"Il faudrait prendre le k le plus petit car cela allège les calculs de voisins","metadata":{}},{"cell_type":"markdown","source":"## Recherche des paramètres optimaux\n- utiliser une gridsearch pour déterminer les meilleurs paramètres, expliquer la valeur de cv","metadata":{"_uuid":"377aed07229608137ddc91785751bebd0de09efe"}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ndef opti(trainx,trainy):\n\n    knn     = KNeighborsClassifier()\n    k_range = list(range(1,21))\n\n    param_grid  = dict(n_neighbors = k_range)\n    grid        = GridSearchCV(knn, param_grid, cv = 10, scoring = 'accuracy')\n    grid_search = grid.fit(trainx, trainy)\n    \n    return grid_search.best_params_['n_neighbors']\nopt = opti(train_X,train_Y)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:51:37.674893Z","iopub.execute_input":"2022-03-27T13:51:37.675626Z","iopub.status.idle":"2022-03-27T13:51:38.974872Z","shell.execute_reply.started":"2022-03-27T13:51:37.675576Z","shell.execute_reply":"2022-03-27T13:51:38.973896Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"markdown","source":"cv représente le nombre de cross-validation","metadata":{}},{"cell_type":"markdown","source":"# Représenter la matrice de confusion sur l'ensemble de validation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nknn = KNeighborsClassifier(n_neighbors = opt)\nknn.fit(train_X,train_Y)\nplot_confusion_matrix(knn, test_X, test_Y)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:51:38.976897Z","iopub.execute_input":"2022-03-27T13:51:38.977267Z","iopub.status.idle":"2022-03-27T13:51:39.242792Z","shell.execute_reply.started":"2022-03-27T13:51:38.977216Z","shell.execute_reply":"2022-03-27T13:51:39.242049Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"markdown","source":"# Créer deux nouvelles bases d'apprentissage une de 100 données, une de 1000 données\n- Observer l'influence de la quantité de données sur les valeurs optimales du paramètre 'k', expliquer\n- Observer l'influence de la quantité de données sur la qualité du résultat obtenu, expliquer (faire attention à mesurer la qualité de l'apprentissage sur l'ensemble validation/test !)\n- Observer l'influence de la quantité de données sur le temps de calcul, expliquer\n\n*NB* : afin d'obtenir des résultats pertinents, il est nécessaire de relancer ce travil un certain nombre de fois afin d'en dégager une tendance statistique.","metadata":{}},{"cell_type":"code","source":"import time\ndfC = donneesSimples(100, sep)\ndfM = donneesSimples(1000, sep)\n\nXC,yC,train_XC, test_XC,train_YC, test_YC = creerBases(dfC)\nXM,yM,train_XM, test_XM,train_YM, test_YM = creerBases(dfM)\n\n#Déterminisation de la valeur optimale k\n\ndebC = time.time() \noptC = opti(train_XC, train_YC)\nfinC = time.time()\n\ndebM = time.time() \noptM = opti(train_XM, train_YM)\nfinM = time.time()\n\nfor k in range(1,6):\n    debC2 = time.time() \n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(train_XC,train_YC)\n    prediction = knn.predict(test_XC)\n    display(\"Acc pour C pour k = \" + str(k) + \" : \" + str(balanced_accuracy_score(test_YC, prediction)))\n    finC2 = time.time() \n    \n    debM2 = time.time() \n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(train_XM,train_YM)\n    prediction = knn.predict(test_XM)\n    display(\"Acc pour M pour k = \" + str(k) + \" : \" + str(balanced_accuracy_score(test_YM, prediction)))\n    finM2 = time.time()\n\ndisplay(\"Valeur optimale pour 100 :\" + str(optC))\ndisplay(\"Valeur optimale pour 1000 :\" + str(optM))\n\ndisplay(\"Temps écoulé pour 100 :\" + str(finC - debC))\ndisplay(\"Temps écoulé pour 100 (knn) :\" + str(finC2 - debC2))\n\ndisplay(\"Temps écoulé pour 1000 :\" + str(finM - debM))\ndisplay(\"Temps écoulé pour 1000 (knn) :\" + str(finM2 - debM2))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:51:39.244221Z","iopub.execute_input":"2022-03-27T13:51:39.244621Z","iopub.status.idle":"2022-03-27T13:51:41.940095Z","shell.execute_reply.started":"2022-03-27T13:51:39.244571Z","shell.execute_reply":"2022-03-27T13:51:41.939130Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"markdown","source":"### Influence sur k\n\nC : 1,4,3,1,1,1,1,1,1,19,1,1,1,1,6,3,1,2,1,1,6,1,1,3,3,16,2,3,1,1<br>\nM : 1,1,1,3,1,8,9,1,1,1,1,3,1,11,1,5,3,1,1,1,1,2,1,1,1,3,1,1,3,1<br>\n\nValeur moyenne:<br>\nC : 2.93<br>\nM : 2.33<br>\n\nAvec un échantillon de 30 valeurs on obtient que le k moyen pour M est inférieur à celui de C.\nCeci peut s'expliquer par le fait que plus on a de points, moins la distance entre ceux-ci est grande, ainsi les voisins ont tendances à être plus \"proche\" que lorsque le nombre de données est faible.","metadata":{}},{"cell_type":"markdown","source":"### Influence sur la précision\n\nRésultats de 3 runs avec 5 précisions pour k allant de 1 à 5:<br>\nC : 0.882, 0.878, 0.925, 0.878, 0.894, 0.778, 0.881, 0.823, 0.881, 0.881, 0.881, 0.849, 0.925, 0.865, 0.910 <br>\nM : 0.980, 0.976, 0.956, 0.967, 0.961, 0.971, 0.976, 0.969, 0.962, 0.952, 0.972, 0.971, 0.968, 0.973, 0.953 <br>\n\nValeur moyenne: <br>\nC : 0.875 <br>\nM : 0.967 <br>\n\nOn remarque une différence de quasiment 10% de précision en plus pour la base contenant 1000 données, ce qui est énorme et montre que plus on a de données, mieux c'est.","metadata":{}},{"cell_type":"markdown","source":"### Influence sur le temps\nC : 1.165, 1.081, 1.097, 1.116, 0.956 <br>\nM : 1.707, 1.764, 1.714, 1.728, 1.351<br>\n\nValeur moyenne:<br>\nC : 1.083<br>\nM : 1.653<br>\n\nMalgré le faible échantillon d'essai on se rend bien compte de manière assez logique que le nombre de données influe sur le temps de résolution de la recherche du k optimal. Plus on a de données, plus il faudra attendre pour résoudre ce problème\n\nOn tire la même conclusion pour le temps de calcul des knn","metadata":{}},{"cell_type":"markdown","source":"---\n# Effet du bruit\nDans cette partie on va examiner la résistance au bruit de l'algorithme, et son influence sur le choix du nombre de voisins.\n---\nCette étude a pour vocation de mieux comprendre le choix des paramètres lorsque certaines données sont incorrectes, ou lorsque le modèle contient des irrégularité non aisément modélisables (par exemple si la classe n'est pas totalement une fonction des entrées).","metadata":{"_kg_hide-input":false}},{"cell_type":"markdown","source":"## Génération des données\nEcrire une fonction prenant en entrée un DataFrame 'T' servant à l'apprentissage et une probabilité $0\\leq p\\leq 1$ qui renvoie un nouveau dataframe qui est une copie de 'T', mais où la classe des exemples a été altérée avec la probabilité $p$ : pour chaque ligne du dataframe, la classe est inchangée avec la probabilité $1-p$, et modifiée avec la probabilité $p$.\n","metadata":{}},{"cell_type":"code","source":"def bruiteur(T,p):\n    noised = T.copy()\n    for i, row in T.iterrows():\n        mod = np.random.random()\n        if(mod <= p):\n            if(row['classe'] == 'A'):\n                noised.loc[i,'classe'] = 'B'\n            if(row['classe'] == 'B'):\n                noised.loc[i,'classe'] = 'A'\n    return noised\n\np = np.random.random()\n\nT = pd.concat([train_X,train_Y], axis = 1)\n\nnoised = bruiteur(T,p)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:51:41.941720Z","iopub.execute_input":"2022-03-27T13:51:41.941967Z","iopub.status.idle":"2022-03-27T13:51:41.987975Z","shell.execute_reply.started":"2022-03-27T13:51:41.941936Z","shell.execute_reply":"2022-03-27T13:51:41.986830Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"markdown","source":"## Analyser l'effet de la force du bruit sur les meilleurs paramètres du modèle\nReprésenter le nombre optimal de voisins à choisir en fonction de la valeur du paramètre $p$.","metadata":{}},{"cell_type":"code","source":"opti_bruit = []\nacc_bruit  = []\ntime_bruit = []\n\nfor i in np.arange(0, 100, 1):\n    \n    start = time.time()\n    noised = bruiteur(T,i/100)\n    XN, yN,train_XN, test_XN,train_YN, test_YN = creerBases(noised)\n    tmp = opti(train_XN,train_YN)\n    opti_bruit.append(tmp)\n    \n    #On prend pour le meilleur nombres de voisins pour chaque modèle\n    knn = KNeighborsClassifier(n_neighbors = tmp)\n    knn.fit(train_XN,train_YN)\n    prediction = knn.predict(test_XN)\n    acc_bruit.append(balanced_accuracy_score(test_YN, prediction))\n    end = time.time()\n    time_bruit.append(end-start)\n    \nsns.lineplot(data = opti_bruit)\nplt.figure()\nsns.lineplot(data = acc_bruit)\nplt.figure()\nsns.lineplot(data = time_bruit)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:51:41.989506Z","iopub.execute_input":"2022-03-27T13:51:41.989920Z","iopub.status.idle":"2022-03-27T13:53:37.812543Z","shell.execute_reply.started":"2022-03-27T13:51:41.989881Z","shell.execute_reply":"2022-03-27T13:53:37.811415Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"markdown","source":"## Conclure, et vérifier l'effet sur les autres paramètres","metadata":{}},{"cell_type":"markdown","source":"### Influence du bruit sur le nombre optimal de k\n\nComme nous pouvons le voir dans le premier graphique, avec un bruit <20% (réciproquement >80%) le nombre de voisins excède rarement les 12. Néanmoins à partir d'une probabilité de 20% de bruit (80% en réciproque) les nombre de voisins semble être totalement aléatoire.\n\n### Influence du bruit sur la précision\n\nPlus le bruit approche les 50% plus la précision fait de même, elle s'approche de l'aléatoire. Ainsi le knn est aussi précis qu'un inconnu qui affirmerait haut et fort l'appartenance à une classe d'une ligne pour chacune.\n\n### Influence du bruit sur le temps\n\nOn observe une croissance du temps de calcul, néanmoins elle est sûrement dû au fait que l'aggrégation se fait de plus en plus probable, donc il y en a plus et cela coûte du temps.\n\n### Conclusion\nLe bruit dans notre cas n'affecte que 2 classes, il serait intéressant d'y faire sur plusieurs afin d'avoir une vraie conclusion sur celui-ci.\nDans notre cas, il s'agit d'une inversion de classe donc les résultats obtenus sont quasi simétriques.","metadata":{}},{"cell_type":"markdown","source":"---\n# Influence des corrélations entre les attributs\n---\nOn travaille à nouveau sur une base de données non bruitée. Ecrire une fonction prenant en entrée un DataFrame de même nature que train ou test, et qui en renvoie une copie à laquelle on a ajouté 5 colonnes définies par :\n- U1 :   $+300 \\times X + 0.1 \\times Y$\n- U2 :   $-4000 \\times X - 0.01 \\times Y$\n- U3 :   $-700 \\times X + 0.12 \\times Y$\n- U4 :   $-280 \\times X + 1.5 \\times Y$\n- U3 :   $+5100 \\times X - 1.2 \\times Y$  \n\nNB : Remettre la colonne ```classe``` en dernière colonne.","metadata":{}},{"cell_type":"code","source":"dfA = donneesSimples(500, sep)\nXA, yA,train_XA, test_XA,train_YA, test_YA = creerBases(dfA)\ndfAT = pd.concat([train_XA, train_YA], axis = 1)\ndfAP = pd.concat([test_XA, test_YA], axis = 1)\n\ndef correlation(df):\n    idx = []\n    u1 = []\n    u2 = []\n    u3 = []\n    u4 = []\n    u5 = []\n    classe = df['classe']\n    df.drop(['classe'], axis=1)\n    for i, row in df.iterrows():\n        \n        # Création des données\n        idx.append(i)\n        u1.append(300*row['abscisse'] + 0.1*row['ordonnée'])\n        u2.append(-4000*row['abscisse'] - 0.01*row['ordonnée'])\n        u3.append(-700*row['abscisse'] + 0.12*row['ordonnée'])\n        u4.append(-280*row['abscisse'] + 1.5*row['ordonnée'])\n        u5.append(5100*row['abscisse'] - .2*row['ordonnée'])\n    \n    # Conversion en Series pour concat\n    u1 = pd.Series(u1,index=idx)\n    u2 = pd.Series(u2,index=idx)\n    u3 = pd.Series(u3,index=idx)\n    u4 = pd.Series(u4,index=idx)\n    u5 = pd.Series(u5,index=idx)  \n    df = pd.concat([df,u1,u2,u3,u4,u5,classe], axis=1)\n    \n    return df\ndfCor = correlation(dfAT)\ndfCor2 = correlation(dfAP)\ndisplay(dfCor.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:53:37.813991Z","iopub.execute_input":"2022-03-27T13:53:37.814247Z","iopub.status.idle":"2022-03-27T13:53:37.918376Z","shell.execute_reply.started":"2022-03-27T13:53:37.814213Z","shell.execute_reply":"2022-03-27T13:53:37.917405Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"markdown","source":"# Observer la diférence de qualité entre :\n- Apprendre en utilisant toutes les observations (x, y, u1, u2, u3, u4, u5)\n- Apprendre en n'utilisant que les observations (x,y)","metadata":{}},{"cell_type":"code","source":"train_X7 = dfCor.copy().drop(['classe'],axis=1)\ntest_X7 = dfCor2.copy().drop(['classe'],axis=1)\n\n# Test avec (x,y,u1,u2,u3,u4,u5) pour X\nopt = opti(train_XA,train_YA)\n\nknn = KNeighborsClassifier(n_neighbors = opt)\nknn.fit(train_X7,train_YA)\nprediction = knn.predict(test_X7)\ndisplay(balanced_accuracy_score(test_YA, prediction)) #Le Y de test ne change pas \n\n\n# Test avec (x,y) pour X\nopt = opti(train_XA,train_YA)\n\nknn = KNeighborsClassifier(n_neighbors = opt)\nknn.fit(train_XA,train_YA)\nprediction = knn.predict(test_XA)\ndisplay(balanced_accuracy_score(test_YA, prediction))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T13:53:37.919627Z","iopub.execute_input":"2022-03-27T13:53:37.919909Z","iopub.status.idle":"2022-03-27T13:53:40.487012Z","shell.execute_reply.started":"2022-03-27T13:53:37.919877Z","shell.execute_reply":"2022-03-27T13:53:40.486089Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"markdown","source":"\n## Expliquer la raison de la différence observée","metadata":{}},{"cell_type":"markdown","source":"Les valeurs de u1,u2,u3,u4,u5 affectent les distances autant que x et y mais sont très axès sur la valeur de X ce qui dérègle l'importance des valeurs d'abscisse et d'ordonnée.<br>\nAu mieux cela n'aurait aucun effet, au pire comme c'est le cas ici présent, cela réduit notre probabilité de bonne prédiction","metadata":{}},{"cell_type":"markdown","source":"## Utiliser un preprocessing adapté sur les données afin que la qualité obtenue en apprenant sur le jeu de données (x, y, u1, u2, u3, u4, u5) soit comparable à celle obtenue en n'utilisant que (x, y)\n\nexpliquer et pointer les limitations, proposer des améliorations\n","metadata":{}},{"cell_type":"markdown","source":"---\n# Merci d'avoir suivi ce TP, j'espère qu'il vous a aidé à mieux appréhender l'utilisation de knn, et vous a permis de faire quelques pas dans le domaine *passionnant* de l'apprentissage artificiel","metadata":{}}]}